{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import mahotas\n",
    "import cv2\n",
    "import os\n",
    "import h5py\n",
    "import h5py\n",
    "import glob\n",
    "import warnings\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Convolution2D,Dense,MaxPool2D,Activation,Dropout,Flatten\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "#parameters\n",
    "images_per_class       = 800\n",
    "fixed_size             = tuple((500, 500))\n",
    "train_path             = \"/Final_Datasets/Diseased_+_Healthy\"\n",
    "h5_train_data          = '/tier1/output/train_data.h5'\n",
    "h5_train_labels        = '/tier1/output/train_labels.h5'\n",
    "bins                   = 8\n",
    "Observe_Image = 'INSERT_IMG_PATH_HERE'\n",
    "\n",
    "resultsdic = {}\n",
    "finalres = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image format conversions\n",
    "def rgb_bgr(image):\n",
    "    rgb_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return rgb_img\n",
    "def bgr_hsv(rgb_img):\n",
    "    hsv_img = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2HSV)\n",
    "    return hsv_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Manipulation\n",
    "def img_segmentation(rgb_img,hsv_img):\n",
    "    lower_green = np.array([25,0,20])\n",
    "    upper_green = np.array([100,255,255])\n",
    "    healthy_mask = cv2.inRange(hsv_img, lower_green, upper_green)\n",
    "    result = cv2.bitwise_and(rgb_img,rgb_img, mask=healthy_mask)\n",
    "    lower_brown = np.array([10,0,10])\n",
    "    upper_brown = np.array([30,255,255])\n",
    "    disease_mask = cv2.inRange(hsv_img, lower_brown, upper_brown)\n",
    "    disease_result = cv2.bitwise_and(rgb_img, rgb_img, mask=disease_mask)\n",
    "    final_mask = healthy_mask + disease_mask\n",
    "    final_result = cv2.bitwise_and(rgb_img, rgb_img, mask=final_mask)\n",
    "    return final_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Manipulation, one of 3 features to alter.\n",
    "def fd_hu_moments(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
    "    return feature\n",
    "\n",
    "def fd_haralick(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    haralick = mahotas.features.haralick(gray).mean(axis=0)\n",
    "    return haralick\n",
    "\n",
    "def fd_histogram(image, mask=None):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist  = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diseased', 'healthy']\n"
     ]
    }
   ],
   "source": [
    "# get the training labels\n",
    "train_labels = os.listdir(train_path)\n",
    "\n",
    "# sort the training labels\n",
    "train_labels.sort()\n",
    "print(train_labels)\n",
    "\n",
    "# declare lists\n",
    "global_features = []\n",
    "global_features1 = []\n",
    "labels          = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/johan/OneDrive/Documents/GitHub/DGMD-S-17/Final_Datasets/Diseased_+_Healthy/diseased\n",
      "processed folder: diseased\n",
      "C:/Users/johan/OneDrive/Documents/GitHub/DGMD-S-17/Final_Datasets/Diseased_+_Healthy/healthy\n",
      "processed folder: healthy\n",
      "Global Feature Extraction DONE\n"
     ]
    }
   ],
   "source": [
    "# loop over the training data sub-folders to iterate over image.\n",
    "for training_name in train_labels:\n",
    "    dir = train_path + \"/\" + training_name\n",
    "    print(dir)\n",
    "    current_label = training_name\n",
    "    #nested loop\n",
    "    for x in os.listdir(dir):\n",
    "        # get the image file name\n",
    "        file = dir + \"/\" + str(x)\n",
    "\n",
    "        # read the image and resize it to a fixed-size\n",
    "        image = cv2.imread(file)\n",
    "        image = cv2.resize(image, fixed_size)\n",
    "        \n",
    "        RGB_BGR       = rgb_bgr(image)\n",
    "        BGR_HSV       = bgr_hsv(RGB_BGR)\n",
    "        IMG_SEGMENT   = img_segmentation(RGB_BGR,BGR_HSV)\n",
    "\n",
    "        # Global Fetaure Descriptor\n",
    "        fv_hu_moments = fd_hu_moments(IMG_SEGMENT)\n",
    "        fv_haralick   = fd_haralick(IMG_SEGMENT)\n",
    "        fv_histogram  = fd_histogram(IMG_SEGMENT)\n",
    "        \n",
    "        # Update\n",
    "        global_feature = np.hstack([fv_histogram, fv_haralick, fv_hu_moments])\n",
    "        labels.append(current_label)\n",
    "        global_features.append(global_feature)\n",
    "    print(\"processed folder: {}\".format(current_label))\n",
    "print(\"Global Feature Extraction DONE\")\n",
    "\n",
    "## TESTING OBSERVE_IMAGE ###\n",
    "file1 = Observe_Image\n",
    "image1 = cv2.imread(file1)\n",
    "image1 = cv2.resize(image1, fixed_size)\n",
    "\n",
    "RGB_BGR1       = rgb_bgr(image1)\n",
    "BGR_HSV1       = bgr_hsv(RGB_BGR1)\n",
    "IMG_SEGMENT1   = img_segmentation(RGB_BGR1,BGR_HSV1)\n",
    "\n",
    "fv_hu_moments1 = fd_hu_moments(IMG_SEGMENT1)\n",
    "fv_haralick1   = fd_haralick(IMG_SEGMENT1)\n",
    "fv_histogram1  = fd_histogram(IMG_SEGMENT1)\n",
    "\n",
    "global_feature1 = np.hstack([fv_histogram, fv_haralick, fv_hu_moments])\n",
    "\n",
    "global_features1.append(global_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] feature vector size (1709, 532)\n"
     ]
    }
   ],
   "source": [
    "# Vector + Training Sizes\n",
    "print(\"[STATUS] feature vector size {}\".format(np.array(global_features).shape))\\\n",
    "print(\"[STATUS] training Labels {}\".format(np.array(labels).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] training labels encoded...\n"
     ]
    }
   ],
   "source": [
    "# Encoding Labels\n",
    "targetNames = np.unique(labels)\n",
    "le          = LabelEncoder()\n",
    "target      = le.fit_transform(labels)\n",
    "print(\"[STATUS] training labels encoded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] feature vector normalized...\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler            = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaled_features = scaler.fit_transform(global_features)\n",
    "rescaled_features1 = scaler.fit_transform(global_features1)\n",
    "print(\"[STATUS] feature vector normalized...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] target labels: [0 0 0 ... 1 1 1]\n",
      "[STATUS] target labels shape: (1709,)\n"
     ]
    }
   ],
   "source": [
    "# Check Status\n",
    "print(\"[STATUS] target labels: {}\".format(target))\n",
    "print(\"[STATUS] target labels shape: {}\".format(target.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6tmATL4_ecG"
   },
   "source": [
    "#### **Save Feature Vector using HDF5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/johan/OneDrive/Documents/GitHub/DGMD-S-17/tier1/output/train_data.h5\n"
     ]
    }
   ],
   "source": [
    "print(h5_train_data)\n",
    "h5f_data = h5py.File(h5_train_data, 'w')\n",
    "h5f_data.create_dataset('dataset_1', data=np.array(rescaled_features))\n",
    "\n",
    "h5f_label = h5py.File(h5_train_labels, 'w')\n",
    "h5f_label.create_dataset('dataset_1', data=np.array(target))\n",
    "\n",
    "h5f_data.close()\n",
    "h5f_label.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6tmATL4_ecG"
   },
   "source": [
    "#### **Algorithm Training**\n",
    "**LR, KNN, SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] features shape: (1709, 532)\n",
      "[STATUS] labels shape: (1709,)\n",
      "[STATUS] training started...\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "#-----------------------------------\n",
    "# TRAINING OUR MODEL\n",
    "#-----------------------------------\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#--------------------\n",
    "# tunable-parameters\n",
    "#--------------------\n",
    "num_trees = 100\n",
    "test_size = 0.20\n",
    "seed      = 9\n",
    "train_path = \"/Final_Datasets/Diseased_+_Healthy\"\n",
    "test_path  = \"/tier1/test\"\n",
    "h5_train_data    = '/tier1/output/train_data.h5'\n",
    "h5_train_labels  = '/tier1/output/train_labels.h5'\n",
    "accuracyscore    = \"accuracy\"\n",
    "\n",
    "# get the training labels\n",
    "train_labels = os.listdir(train_path)\n",
    "\n",
    "# sort the training labels\n",
    "train_labels.sort()\n",
    "\n",
    "if not os.path.exists(test_path):\n",
    "    os.makedirs(test_path)\n",
    "\n",
    "# create all the machine learning models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(random_state=seed)))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('SVM', SVC(random_state=seed)))\n",
    "\n",
    "\n",
    "# variables to hold the results and names\n",
    "results = []\n",
    "names   = []\n",
    "\n",
    "# import the feature vector and trained labels\n",
    "h5f_data  = h5py.File(h5_train_data, 'r')\n",
    "h5f_label = h5py.File(h5_train_labels, 'r')\n",
    "\n",
    "global_features_string = h5f_data['dataset_1']\n",
    "global_labels_string   = h5f_label['dataset_1']\n",
    "\n",
    "global_features = np.array(global_features_string)\n",
    "global_labels   = np.array(global_labels_string)\n",
    "\n",
    "h5f_data.close()\n",
    "h5f_label.close()\n",
    "\n",
    "# verify the shape of the feature vector and labels\n",
    "print(\"[STATUS] features shape: {}\".format(global_features.shape))\n",
    "print(\"[STATUS] labels shape: {}\".format(global_labels.shape))\n",
    "print(\"[STATUS] training started...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] split train and test data...\n",
      "Train data  : (1367, 532)\n",
      "Test data   : (342, 532)\n"
     ]
    }
   ],
   "source": [
    "# Split Data\n",
    "(trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal) = train_test_split(np.array(global_features),\n",
    "                                                                                          np.array(global_labels),\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                          random_state=seed)\n",
    "\n",
    "print(\"[STATUS] split train and test data...\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1367, 532)\n"
     ]
    }
   ],
   "source": [
    "trainDataGlobal\n",
    "print(trainDataGlobal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.917341 (0.043566)\n",
      "KNN: 0.930523 (0.025313)\n",
      "SVM: 0.918076 (0.038037)\n"
     ]
    }
   ],
   "source": [
    "# 10-fold CV, iterating over the three algorithms.\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = cross_val_score(model, trainDataGlobal, trainLabelsGlobal, cv=kfold, scoring=accuracyscore)\n",
    "    names.append(name)\n",
    "    resultsdic[name] = cv_results.mean()\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN has highest score. Using KNeighborsClassifier()\n",
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "Keymax = max(zip(resultsdic.values(), resultsdic.keys()))[1]\n",
    "ik = 0\n",
    "while ik < len(models) - 1:\n",
    "    if Keymax == models[ik][0]:\n",
    "        m = models[ik][1]\n",
    "        print(Keymax + ' has highest score. Using ' + str(m))\n",
    "    else:\n",
    "        pass\n",
    "    ik += 1\n",
    "\n",
    "m.fit(trainDataGlobal, trainLabelsGlobal)\n",
    "y_predict = m.predict(rescaled_features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy score for Tier 1: 0.9269005847953217\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testLabelsGlobal,y_predict))\n",
    "\n",
    "# Final Accuracy Score\n",
    "from sklearn.metrics import accuracy_score\n",
    "tier1_accuracy_score = accuracy_score(testLabelsGlobal, y_predict)\n",
    "print('Overall Accuracy score for Tier 1: ' + str(tier1_accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6tmATL4_ecG"
   },
   "source": [
    "#### **Test-Train Data**\n",
    "**Split the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "907a8041"
   },
   "outputs": [],
   "source": [
    "def get_files(directCNN):\n",
    "  if not os.path.exists(directCNN):\n",
    "    return 0\n",
    "  count=0\n",
    "  for current_path,dirs,files in os.walk(directCNN):\n",
    "    for dr in dirs:\n",
    "      count+= len(glob.glob(os.path.join(current_path,dr+\"/*\")))\n",
    "  return count\n",
    "train_dir =\"/Final_Datasets/CNN_Dataset\"\n",
    "test_dir = \"/tier2/test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a07bcaa8",
    "outputId": "66fa1298-e35a-466b-e130-57aba5081e4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 Classes\n",
      "30247 Train images\n",
      "0 Test images\n"
     ]
    }
   ],
   "source": [
    "#image count\n",
    "train_samples =get_files(train_dir)\n",
    "num_classes=len(glob.glob(train_dir+\"/*\"))\n",
    "test_samples=get_files(test_dir)\n",
    "print(num_classes,\"Classes\")\n",
    "print(train_samples,\"Train images\")\n",
    "print(test_samples,\"Test images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuGK0vnQ_jRe"
   },
   "source": [
    "#### **Image Augumentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "d3d73be1"
   },
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    "    )\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6WpHBoue9d3M",
    "outputId": "374ea870-631c-4fd8-d6a5-17d03d8d7b90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30247 images belonging to 25 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "input_shape=(224,224,3)\n",
    "tgen =train_datagen.flow_from_directory(train_dir,target_size=(224,224),batch_size=32)\n",
    "test_generator=test_datagen.flow_from_directory(test_dir,shuffle=True,target_size=(224,224),batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHhlQnxs_SXv"
   },
   "source": [
    "#### **CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c7b4d1a",
    "outputId": "5f6d1d65-0079-44c9-8dd2-070697dff741"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 220, 220, 32)      2432      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 73, 73, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 71, 71, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 35, 35, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 33, 33, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               8389120   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 25)                3225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,488,185\n",
      "Trainable params: 8,488,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5),input_shape=input_shape,activation='relu',name=\"conv2d_1\"))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3),name=\"max_pooling2d_1\"))\n",
    "model.add(Conv2D(32, (3, 3),activation='relu',name=\"conv2d_2\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name=\"max_pooling2d_2\"))\n",
    "model.add(Conv2D(64, (3, 3),activation='relu',name=\"conv2d_3\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name=\"max_pooling2d_3\"))   \n",
    "model.add(Flatten(name=\"flatten_1\"))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128,activation='relu'))          \n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6daeef2d",
    "outputId": "87c475e4-1c41-45dd-9c9d-f438f3b5cfae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "                       test_dir,\n",
    "                       target_size=(224, 224),\n",
    "                       batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "8d3b4edf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "946/946 [==============================] - ETA: 0s - loss: 1.1155 - accuracy: 0.6633WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "946/946 [==============================] - 539s 569ms/step - loss: 1.1155 - accuracy: 0.6633 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "946/946 [==============================] - ETA: 0s - loss: 0.4915 - accuracy: 0.8383WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "946/946 [==============================] - 489s 517ms/step - loss: 0.4915 - accuracy: 0.8383 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "history1 = model.fit(\n",
    "    tgen,#egitim verileri\n",
    "    steps_per_epoch=None,\n",
    "    epochs=2,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=None,\n",
    "    verbose=1,\n",
    "    callbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.3,patience=3, min_lr=0.000001)],\n",
    "    shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "a616bb60"
   },
   "outputs": [],
   "source": [
    "model.save('/tier2/plant_disease_Cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YybBG0FDCCMQ"
   },
   "source": [
    "#### **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "bc186b0d",
    "outputId": "480c8413-d16a-446f-a3c7-de419d0063dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "PATH\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'PATH'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-167-d839fe0915b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mObserve_Image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mresult_cnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_cnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mObserve_Image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mdisease\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mObserve_Image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-167-d839fe0915b6>\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\johan\\anaconda3\\lib\\site-packages\\keras\\utils\\image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m       \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m       \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PATH'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_cnn=load_model('/tier2/plant_disease_Cnn.h5')\n",
    "\n",
    "def prepare(imgPATH):\n",
    "    img = tf.keras.utils.load_img(imgPATH, target_size=(224,224))\n",
    "    img2 = tf.keras.utils.img_to_array(img)\n",
    "    img2 = img2/255\n",
    "    return np.expand_dims(img2, axis=0)\n",
    "\n",
    "#Looping over images in testing.\n",
    "for test_file in os.listdir(test_dir):\n",
    "    #print(test_file)\n",
    "    classes=list(tgen.class_indices.keys())\n",
    "    flink = test_dir + '/' + test_file\n",
    "    cnnresult = model_cnn.predict([prepare(flink)]) #Passes through the model after preparing the image.\n",
    "    disease = mpimg.imread(flink)\n",
    "    plt.figure()\n",
    "    #plt.imshow(disease) #present images as figure\n",
    "\n",
    "    classresult=np.argmax(cnnresult,axis=1)\n",
    "    #print(classes[classresult[0]])\n",
    "\n",
    "print(Observe_Image)\n",
    "classes=list(tgen.class_indices.keys())\n",
    "cnnresult = model_cnn.predict([prepare(Observe_Image)]) \n",
    "disease = mpimg.imread(Observe_Image)\n",
    "plt.figure()\n",
    "plt.imshow(disease)\n",
    "classresult=np.argmax(cnnresult,axis=1)\n",
    "print(classes[classresult[0]])\n",
    "if y_predict[0] == 1:\n",
    "    if classes[classresult[0]].find('healthy') == -1:\n",
    "        print('True_Positive')\n",
    "    else:\n",
    "        print('False_Negative')\n",
    "else:\n",
    "    if classes[classresult[0]].find('healthy') == -1:\n",
    "        print('False_Positive')\n",
    "    else:\n",
    "        print('True_Negative')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "04c2774e0eee72fdf7c569530da90ed42b07f746012a791613028ba7115aa244"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
